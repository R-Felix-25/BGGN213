---
title: "class07: Machine Learning 1"
author: "Rachel (PID:A16037641)"
format: pdf
---

Today we will begin our exploration of some "classical" machine learnign approaches. We will start with clustering: 

Let's first make up some data to cluster where we know what the answer should be. 

```{r}
hist(rnorm(1000))

```

```{r}
x <- c( rnorm(30, mean=-3), rnorm(30, mean=+3))
y<- rev(x)
x <- cbind(x,y)
head(x)
```

Peek at x with `plot()`
```{r}
plot(x)
```

Then main function in "base" R for K-means clustering is called `kmeans()`. 
```{r}
k <- kmeans(x, centers=2)
k
```

> Q. How big are the clusters (i.e their size)?

```{r}
k$size
```

> Q. What clusters do my data points reside in? What are my cluster results? 

```{r}
k$cluster
```


> Q. Make a plot of our data colored by clsuter assignment - i.e. Make a rsult figure...

```{r}
plot(x, col=k$cluster)
points(k$centers,col="blue", pch=15)
```

>Q. Cluster with k-means into 4 clusters and plot your results as above. 

```{r}
k4 <- kmeans(x, centers=4)
plot(x, col=k4$cluster)
points(k4$centers,col="blue", pch=15)
```


>Q. Run kmeans with centers (i.e. values of k) equal 1 to 6

```{r}
k$tot.withinss
k1 <-kmeans(x, centers=1)$tot.withinss
k2 <-kmeans(x, centers=1)$tot.withinss
k3 <-kmeans(x, centers=1)$tot.withinss
k4 <-kmeans(x, centers=1)$tot.withinss
k5 <-kmeans(x, centers=1)$tot.withinss
k6 <-kmeans(x, centers=1)$tot.withinss

ans <- c(k1,k2,k3,k4,k5,k6)


```

Or use a for loop

```{r}
ans <- NULL
for(i in 1:6) {
  ans <- c(ans, kmeans(x, centers=i)$tot.withinss)
}
```

Make a "scree-plot'
```{r}
ans
plot(ans, typ="b")
```


## Hierarchiacal Clustering

The main function in "base" R for this is called `hclust()`

```{r}
d <- dist(x)
hc <- hclust(d)
hc
```

```{r}
plot(hc)
abline(h=7, col='red')
```

To obtain clusters from our `hclust` result object **hc** we "cut" the tree fo yield different sub branches. For this we use the `cutree()` function. 
```{r}
grps <- cutree(hc, h=7)
grps
```

```{r}
plot(x, col=grps)
```

## Principal Componenet Analysis (PCA)

```{r}
url <- "https://tinyurl.com/UK-foods"
x <- read.csv(url)
```

> Q1. How many rows and columns are in your new data frame named x? What R functions could you use to answer this questions?

```{r}
dim(x) 
```

## Preview the first 6 rows

```{r}
head(x)
```

Fix the amount of rows
```{r}
# Note how the minus indexing works
rownames(x) <- x[,1]
x <- x[,-1]
head(x)
```

Now lets check the dimensions again:
```{r}
dim(x)
```

Side-note: An alternative approach to setting the correct row-names in this case would be to read the data file again and this time set the row.names argument of read.csv() to be the first column (i.e. use argument setting row.names=1), see below:
```{r}
x <- read.csv(url, row.names=1)
head(x)
```

> Q2. Which approach to solving the ‘row-names problem’ mentioned above do you prefer and why? Is one approach more robust than another under certain circumstances?

If you run `x <- x[,-1]` multiple times, you remove a column every time you run a code chunk. So the best way to run this is reading the data the correct way using `x <- read.csv(url, row.names=1)` 

## Spotting major differences and trends

```{r}
# Using base R
barplot(as.matrix(x), beside=T, col=rainbow(nrow(x)))
```

> Q3: Changing what optional argument in the above barplot() function results in the following plot?

If you change the `beside=T` to `beside=F`

```{r}
barplot(as.matrix(x), beside=F, col=rainbow(nrow(x)))
```

# Currently we have wide format 
Data organized with one row per Food (17 observation) and multiple columns for Country (4 different measurements across a row):
```{r}
dim(x)
```

To convert this to “long” format we want one row per measurement - maximizes rows (17x4=68), minimizes columns (with a singe Consumption measurement value per Country). We will do tidying with the pivot_longer() function from the tidyr package:

```{r}
library(tidyr)

# Convert data to long format for ggplot with `pivot_longer()`
x_long <- x |> 
          tibble::rownames_to_column("Food") |> 
          pivot_longer(cols = -Food, 
                       names_to = "Country", 
                       values_to = "Consumption")

dim(x_long)
```

```{r}
head(x_long)
```

```{r}
# Create grouped bar plot
library(ggplot2)

ggplot(x_long) +
  aes(x = Country, y = Consumption, fill = Food) +
  geom_col(position = "dodge") +
  theme_bw()
```

> Q4: Changing what optional argument in the above ggplot() code results in a stacked barplot figure?







> Q5: We can use the pairs() function to generate all pairwise plots for our countries. Can you make sense of the following code and resulting figure? What does it mean if a given point lies on the diagonal for a given plot?

In the y axis of every plot in the first row, England is on the y-axis and Wales on the x-axis, the same pattern goes for all the rest of the rows. The points represent all the different foods. Points on the diagonal mean these foods are consumed similar between countries. 

```{r}
pairs(x, col=rainbow(nrow(x)), pch=16)
```


```{r}
library(pheatmap)

pheatmap( as.matrix(x) )
```

>Q6. Based on the pairs and heatmap figures, which countries cluster together and what does this suggest about their food consumption patterns? Can you easily tell what the main differences between N. Ireland and the other countries of the UK in terms of this data-set?

It looks like Wales and England are quite similar in their consumption of these foods. it is sill quite difficult to tell what is going on in the dataset. 

## PCA to the rescue

The main funciton in "base" R for PCA is called `prcomp()`. 

As we want to do PCA on the food data for the different countries we will want the foods in the columns.


```{r}
pca <- prcomp( t(x) )
summary(pca)
```

Our result object is called `pca` and it has a `$x` component that we will look at first

> Q8. Customize your plot so that the colors of the country names match the colors in our UK and Ireland map and table at start of this document.

```{r}
library(ggplot2)
cols <- c("orange", "red", "blue", "darkgreen")
ggplot(pca$x) + 
  aes(PC1, PC2, label=rownames(pca$x)) +
  geom_point(size = 3) +
  geom_text(col=cols)

```

We can use the square of pca$sdev , which stands for “standard deviation”, to calculate how much variation in the original data each PC accounts for.

```{r}
v <- round( pca$sdev^2/sum(pca$sdev^2) * 100 )
v
```
```{r}
## or the second row here...
z <- summary(pca)
z$importance
```
```{r}
# Create scree plot with ggplot
variance_df <- data.frame(
  PC = factor(paste0("PC", 1:length(v)), levels = paste0("PC", 1:length(v))),
  Variance = v
)

ggplot(variance_df) +
  aes(x = PC, y = Variance) +
  geom_col(fill = "steelblue") +
  xlab("Principal Component") +
  ylab("Percent Variation") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 0))
```

## Digging deeper (variable loadings)

Another major result out of PCA is the so-called "variable loadings" or `$rotation` that tells us how the original variables (foods) contribute to PCs (i.e. our new axis)

```{r}
ggplot(pca$rotation) +
  aes(PC1, rownames(pca$rotation)) +
  geom_col()

```

```{r}
## Lets focus on PC1 as it accounts for > 90% of variance 
ggplot(pca$rotation) +
  aes(x = PC1, 
      y = reorder(rownames(pca$rotation), PC1)) +
  geom_col(fill = "steelblue") +
  xlab("PC1 Loading Score") +
  ylab("") +
  theme_bw() +
  theme(axis.text.y = element_text(size = 9))
```

> Q9: Generate a similar ‘loadings plot’ for PC2. What two food groups feature prominantely and what does PC2 maninly tell us about?

We can see when we plot PC2 there are two outliers, one being for fresh potatoes and the other soft drinks

```{r}
ggplot(pca$rotation) +
  aes(x = PC2, 
      y = reorder(rownames(pca$rotation), PC2)) +
  geom_col(fill = "steelblue") +
  xlab("PC2 Loading Score") +
  ylab("") +
  theme_bw() +
  theme(axis.text.y = element_text(size = 9))
```



## PCA of RNA-seq data

```{r}
url2 <- "https://tinyurl.com/expression-CSV"
rna.data <- read.csv(url2, row.names=1)
head(rna.data)
```


>Q10: How many genes and samples are in this data set?

There are 100 rows, and 10 columns
```{r}
dim(rna.data)
```

```{r}
## Again we have to take the transpose of our data 
pca <- prcomp(t(rna.data), scale=TRUE)

# Create data frame for plotting
df <- as.data.frame(pca$x)
df$Sample <- rownames(df)

## Plot with ggplot
ggplot(df) +
  aes(x = PC1, y = PC2, label = Sample) +
  geom_point(size = 3) +
  geom_text(vjust = -0.5, size = 3) +
  xlab("PC1") +
  ylab("PC2") +
  theme_bw()
```

```{r}
summary(pca)
```

A quick scree plot summary of this Proportion of Variance for each PC can be obtained using ggplot:

```{r}
# Calculate variance explained
pca.var <- pca$sdev^2
pca.var.per <- round(pca.var/sum(pca.var)*100, 1)

# Create scree plot data
scree_df <- data.frame(
  PC = factor(paste0("PC", 1:10), levels = paste0("PC", 1:10)),
  Variance = pca.var[1:10]
)

ggplot(scree_df) +
  aes(x = PC, y = Variance) +
  geom_col(fill = "steelblue") +
  ggtitle("Quick scree plot") +
  xlab("Principal Component") +
  ylab("Variance") +
  theme_bw()

```
```{r}
## Percent variance is often more informative to look at 
pca.var.per
```
```{r}
# Create percent variance scree plot
scree_pct_df <- data.frame(
  PC = factor(paste0("PC", 1:10), levels = paste0("PC", 1:10)),
  PercentVariation = pca.var.per[1:10]
)

ggplot(scree_pct_df) +
  aes(x = PC, y = PercentVariation) +
  geom_col(fill = "steelblue") +
  ggtitle("Scree Plot") +
  xlab("Principal Component") +
  ylab("Percent Variation") +
  theme_bw()
```

A better looking graph: 
```{r}
## A vector of colors for wt and ko samples
colvec <- colnames(rna.data)
colvec[grep("wt", colvec)] <- "red"
colvec[grep("ko", colvec)] <- "blue"

# Add condition to data frame
df$condition <- substr(df$Sample, 1, 2)
df$color <- colvec

ggplot(df) +
  aes(x = PC1, y = PC2, color = color, label = Sample) +
  geom_point(size = 3) +
  geom_text(vjust = -0.5, hjust = 0.5, show.legend = FALSE) +
  scale_color_identity() +
  xlab(paste0("PC1 (", pca.var.per[1], "%)")) +
  ylab(paste0("PC2 (", pca.var.per[2], "%)")) +
  theme_bw()
```

## Gene Loadings

```{r}
loading_scores <- pca$rotation[,1]

## Find the top 10 measurements (genes) that contribute
## most to PC1 in either direction (+ or -)
gene_scores <- abs(loading_scores) 
gene_score_ranked <- sort(gene_scores, decreasing=TRUE)

## show the names of the top 10 genes
top_10_genes <- names(gene_score_ranked[1:10])
top_10_genes 
```

